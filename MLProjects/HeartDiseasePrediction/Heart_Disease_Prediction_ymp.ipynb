{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement:\n",
    "You are the data scientist at a medical research facility. The facility wants you to\n",
    "build a machine learning model to classify if the given data of a patient should tell\n",
    "if the patient is at the risk of a heart attack.\n",
    "\n",
    "Heart Disease Dataset:\n",
    "UCI Heart Disease Dataset\n",
    "(https://archive.ics.uci.edu/ml/datasets/Heart+Disease?spm=5176.100239.blogco\n",
    "nt54260.8.TRNGoO)\n",
    "\n",
    "### Lab Environment:\n",
    "Jupyter Notebooks\n",
    "\n",
    "### Domain:\n",
    "Healthcare\n",
    "\n",
    "### Tasks To Be Performed:\n",
    "\n",
    "1. Data Analysis:\n",
    "a. Import the dataset\n",
    "b. Get information about the dataset (mean, max, min, quartiles etc.)\n",
    "c. Find the correlation between all fields\n",
    "\n",
    "2. Data Visualization:\n",
    "a. Visualize the number of patients having a heart disease and not having\n",
    "a heart disease\n",
    "b. Visualize the age and whether a patient has disease or not\n",
    "c. Visualize correlation between all features using a heat map\n",
    "\n",
    "3. Logistic Regression:\n",
    "a. Build a simple logistic regression model:\n",
    "i. Divide the dataset in 70:30 ratio\n",
    "ii. Build the model on train set and predict the values on test set\n",
    "iii. Build the confusion matrix and get the accuracy score\n",
    "\n",
    "4. Decision Tree:\n",
    "a. Build a decision tree model:\n",
    "i. Divide the dataset in 70:30 ratio\n",
    "ii. Build the model on train set and predict the values on test set\n",
    "iii. Build the confusion matrix and calculate the accuracy\n",
    "iv. Visualize the decision tree using the Graphviz package\n",
    "\n",
    "5. Random Forest:\n",
    "a. Build a Random Forest model:\n",
    "i. Divide the dataset in 70:30 ratio\n",
    "ii. Build the model on train set and predict the values on test set\n",
    "iii. Build the confusion matrix and calculate the accuracy\n",
    "iv. Visualize the model using the Graphviz package\n",
    "\n",
    "6. Select the best model\n",
    "a. Print the confusion matrix of all classifiers\n",
    "b. Print the classification report of all classifiers\n",
    "c. Calculate Recall Precision and F1 score of all the models\n",
    "d. Visualize confusion matrix using heatmaps\n",
    "e. Select the best model based on the best accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting graphviz\n",
      "  Obtaining dependency information for graphviz from https://files.pythonhosted.org/packages/00/be/d59db2d1d52697c6adc9eacaf50e8965b6345cc143f671e1ed068818d5cf/graphviz-0.20.3-py3-none-any.whl.metadata\n",
      "  Downloading graphviz-0.20.3-py3-none-any.whl.metadata (12 kB)\n",
      "Downloading graphviz-0.20.3-py3-none-any.whl (47 kB)\n",
      "   ---------------------------------------- 0.0/47.1 kB ? eta -:--:--\n",
      "   ---------------------------------- ----- 41.0/47.1 kB 960.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 47.1/47.1 kB 784.8 kB/s eta 0:00:00\n",
      "Installing collected packages: graphviz\n",
      "Successfully installed graphviz-0.20.3\n"
     ]
    }
   ],
   "source": [
    "! pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier, export_text, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import *\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn import tree\n",
    "import graphviz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A) DATA ANALYSIS\n",
    "\n",
    "a. Import the dataset\n",
    "\n",
    "b. Get information about dataset (mean, max, min, quartiles etc.)\n",
    "\n",
    "c. Find the correlation between all fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'dataset.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m df\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1662\u001b[0m     f,\n\u001b[0;32m   1663\u001b[0m     mode,\n\u001b[0;32m   1664\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1665\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1666\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1667\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1668\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1669\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1670\u001b[0m )\n\u001b[0;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    860\u001b[0m             handle,\n\u001b[0;32m    861\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    862\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    863\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    864\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    865\u001b[0m         )\n\u001b[0;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dataset.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('dataset.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B) DATA VISUALIZATION:\n",
    "\n",
    "a. Visualize the number of patients having a heart disease and not having a heart disease.\n",
    "\n",
    "b. Visualize the age and weather patient has disease or not\n",
    "\n",
    "c. Visualize correlation between all features using a heat map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f = plt.figure(figsize=(5, 7))\n",
    "custom_lines = [Line2D([0], [0], color='blue', lw=2),Line2D([0], [0], color='orange', lw=2)]\n",
    "\n",
    "barPlot = sns.barplot(x=df['target'].value_counts().index, y=df['target'].value_counts().values, palette=['blue', 'orange'])\n",
    "                      \n",
    "plt.xlabel('Count of People with and without Heart Disease')\n",
    "plt.ylabel('Count')\n",
    "plt.bar_label(barPlot.containers[0])\n",
    "plt.legend(custom_lines, ['No Heart Disease', 'Heart Disease'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(12, 4))\n",
    "sns.scatterplot(x=df['age'], y=df['target'], color='red')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 10))\n",
    "sns.heatmap(df.corr(), annot = True)\n",
    "plt.savefig('Correlation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C) LOGISTIC REGRESSION\n",
    "\n",
    "a. Build a simple logistic regression model\n",
    "\n",
    "i. Divide the dataset in 70:30 ratio\n",
    "\n",
    "ii. Build the model on train set and predict the values on test set\n",
    "\n",
    "iii. Build the confusion matrix and get the accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.iloc[:,:-1]\n",
    "y = df['target']\n",
    "\n",
    "stdScalar = StandardScaler()\n",
    "x = stdScalar.fit_transform(x)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3,random_state=67)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticModel = LogisticRegression()\n",
    "logisticModel.fit(x_train, y_train)\n",
    "y_pred1 = logisticModel.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_error1 = pd.DataFrame()\n",
    "pred_error1['Actual'] = y_test\n",
    "pred_error1['Predicted'] = y_pred1\n",
    "pred_error1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = confusion_matrix(y_test, y_pred1)\n",
    "c1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = accuracy_score(y_test, y_pred1)*100\n",
    "a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report1 = classification_report(y_test, y_pred1, output_dict=True)\n",
    "report1 = pd.DataFrame(report1).transpose()\n",
    "print(report1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision1 = precision_score(y_test, y_pred1)*100\n",
    "recall1 = recall_score(y_test, y_pred1)*100\n",
    "f1Score1 = f1_score(y_test, y_pred1)*100\n",
    "print(\"Precision:\", precision1, \"\\nRecall Score:\", recall1, \"\\nF1Score:\", f1Score1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D) DECISION TREE:\n",
    "\n",
    "a. Build a decision tree model\n",
    "\n",
    "i. Divide the dataset in 70:30 ratio\n",
    "\n",
    "ii. Build the model on train set and predict the values on test set\n",
    "\n",
    "iii. Build the confusion matrix and calculate the accuracy\n",
    "\n",
    "iv. Visualize the decision tree using the graphviz package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treeModel = DecisionTreeClassifier(criterion='entropy', max_depth=3)\n",
    "treeModel.fit(x_train, y_train)\n",
    "y_pred2 = treeModel.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_error2 = pd.DataFrame()\n",
    "pred_error2['Actual'] = y_test\n",
    "pred_error2['Predicted'] = y_pred2\n",
    "pred_error2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2 = confusion_matrix(y_test, y_pred2)\n",
    "c2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2 = accuracy_score(y_test, y_pred2)*100\n",
    "a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report2 = classification_report(y_test, y_pred2, output_dict=True)\n",
    "report2 = pd.DataFrame(report2).transpose()\n",
    "print(report2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision2 = precision_score(y_test, y_pred2)*100\n",
    "recall2 = recall_score(y_test, y_pred2)*100\n",
    "f1Score2 = f1_score(y_test, y_pred2)*100\n",
    "print(\"Precision:\", precision2, \"\\nRecall Score:\", recall2, \"\\nF1Score:\", f1Score2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_List = []\n",
    "\n",
    "col_List = list(df.columns)\n",
    "col_List.pop(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# graph_data = tree.export_graphviz(treeModel, out_file=None, \n",
    "#                                 feature_names=col_List,  \n",
    "#                                 class_names='target',\n",
    "#                                 rounded=True,\n",
    "#                                 filled=True)\n",
    "\n",
    "# graph = graphviz.Source(graph_data) \n",
    "# graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the decision tree\n",
    "plt.figure(figsize=(15, 10))\n",
    "tree.plot_tree(treeModel, feature_names=col_List, class_names='target', filled=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E) RANDOM FOREST:\n",
    "\n",
    "a. Build a Random Forest model \n",
    "\n",
    "i. Divide the dataset in 70:30 ratio\n",
    "\n",
    "ii. Build the model on train set and predict the values on test set\n",
    "\n",
    "iii. Build the confusion matrix and calculate the accuracy\n",
    "\n",
    "iv. Visualize the model using the graphviz package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomForestModel = RandomForestClassifier(n_estimators=20)\n",
    "randomForestModel.fit(x_train, y_train)\n",
    "y_pred3 = randomForestModel.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_error3 = pd.DataFrame()\n",
    "pred_error3['Actual'] = y_test\n",
    "pred_error3['Predicted'] = y_pred3\n",
    "pred_error3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c3 = confusion_matrix(y_test, y_pred3)\n",
    "c3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a3 = accuracy_score(y_test, y_pred3)*100\n",
    "a3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report3 = classification_report(y_test, y_pred3, output_dict=True)\n",
    "report3 = pd.DataFrame(report3).transpose()\n",
    "print(report3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision3 = precision_score(y_test, y_pred3)*100\n",
    "recall3 = recall_score(y_test, y_pred3)*100\n",
    "f1Score3 = f1_score(y_test, y_pred3)*100\n",
    "print(\"Precision:\", precision3, \"\\nRecall Score:\", recall3, \"\\nF1Score:\", f1Score3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph_data = tree.export_graphviz(randomForestModel.estimators_[0], out_file=None, \n",
    "#                                 feature_names=col_List,  \n",
    "#                                 class_names='target',\n",
    "#                                 rounded=True,\n",
    "#                                 filled=True)\n",
    "\n",
    "# graph = graphviz.Source(graph_data) \n",
    "# graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "tree.plot_tree(randomForestModel.estimators_[0], feature_names=col_List, class_names='target', filled=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F) SELECT THE BEST MODEL\n",
    "\n",
    "a. Print the confusion matrix of all classifiers\n",
    "\n",
    "b. Print the classification report of all classifiers\n",
    "\n",
    "c. Calculate Recall Precision and F1 score of all the models\n",
    "\n",
    "d. Visualize confusion matrix using heatmaps \n",
    "\n",
    "e. Select the best model based on the best accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelMetrics = pd.DataFrame()\n",
    "modelMetrics['Model Name'] = ['Logictic Regression', 'Decision Tree Classifier', 'Random Forest Classifier']\n",
    "modelMetrics['Confusion Matrix'] = [c1, c2, c3]\n",
    "modelMetrics['Precision'] = [precision1, precision2, precision3]\n",
    "modelMetrics['Recall Score'] = [recall1, recall2, recall3]\n",
    "modelMetrics['F1 Score'] = [f1Score1, f1Score2, f1Score3]\n",
    "modelMetrics['Accuracy'] = [a1, a2, a3]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('expand_frame_repr', False)\n",
    "print(modelMetrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1,3, figsize=(17, 4))\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.heatmap(c1, annot=True, fmt='G')\n",
    "plt.title('Logistic Regression')\n",
    "# plt.show()\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.heatmap(c2, annot=True, fmt='G')\n",
    "plt.title('Decision Tree Classifier')\n",
    "# plt.show()\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.heatmap(c3, annot=True, fmt='G')\n",
    "plt.title('Random Forest Classifier')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Logistic Regression Classification Report\\n\", report1, \n",
    "      \"\\n\\nDecision Tree Classification Report\\n\", report2, \n",
    "      \"\\n\\nRandom Forest Classification Report\\n\", report3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From the Accuracy percentage it is clear that Random Forest Classifier Model has performed the Best among the other classifier models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
